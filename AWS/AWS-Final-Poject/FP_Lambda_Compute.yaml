AWSTemplateFormatVersion: '2010-09-09'
Description: 'Serverless compute and storage layer connecting Kinesis → Lambda → S3 → DynamoDB with validation, enrichment, and aggregation logic.'

Resources:

#####################
# Lambda Functions  #
#####################

  ValidatorEnricherLambda:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: validator_enricher
      Description: 'Validates and enriches incoming events from Kinesis, writes to S3.'
      Runtime: python3.12
      Handler: index.validator
      Environment:
        Variables:
          RAW_BUCKET: !Ref S3Raw
          PROCESSED_BUCKET: !Ref S3Processed
      DeadLetterConfig:
        TargetArn: !ImportValue Streaming-ValidatorDLQArn
      Role: !ImportValue All-Mighty-Lambda
      Code:
        ZipFile: |
          import json
          import boto3
          import os
          import base64
          from datetime import datetime
          s3 = boto3.client("s3")
          raw_bucket = os.environ["RAW_BUCKET"]
          processed_bucket = os.environ["PROCESSED_BUCKET"]

          def validator(event, context):
              output = []
              for record in event.get("Records", []):
                  try:
                      payload = base64.b64decode(record["kinesis"]["data"]).decode("utf-8")
                      s3.put_object(
                          Bucket=raw_bucket,
                          Key=f"raw/{datetime.utcnow().timestamp()}.json",
                          Body=payload
                      )
                      data = json.loads(payload)
                      if "symbol" not in data or "price" not in data:
                          raise ValueError("Missing required fields")
                      data["validated_at"] = datetime.utcnow().isoformat()
                      output.append(data)
                      s3.put_object(
                          Bucket=processed_bucket,
                          Key=f"validated/{data['symbol']}-{datetime.utcnow().timestamp()}.json",
                          Body=json.dumps(data)
                      )
                  except Exception as e:
                      print(f"Bad record skipped: {e}")
              print(f"Validated batch: {output}")
              return output


  AggregatorLambda:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: aggregator
      Description: 'Triggered by S3 (Processed), aggregates events, writes results to DynamoDB.'
      Runtime: python3.12
      Handler: index.aggregator
      Environment:
        Variables:
          METRICS_TABLE: !ImportValue FP-Datastores-MetricsTable
      Role: !ImportValue All-Mighty-Lambda
      DeadLetterConfig:
        TargetArn: !ImportValue Streaming-AggregatorDLQArn
      Code:
        ZipFile: |
          import json, boto3, os
          from datetime import datetime

          s3 = boto3.client("s3")
          dynamodb = boto3.resource("dynamodb")
          table = dynamodb.Table(os.environ["METRICS_TABLE"])

          def aggregator(event, context):
              aggregates = {}
              for record in event["Records"]:
                  bucket = record["s3"]["bucket"]["name"]
                  key = record["s3"]["object"]["key"]
                  response = s3.get_object(Bucket=bucket, Key=key)
                  data = json.loads(response["Body"].read().decode("utf-8"))
                  key_field = data.get("symbol") or data.get("city")
                  price = data.get("price")
                  if key_field and isinstance(price, (int, float)):
                      aggregates.setdefault(key_field, []).append(price)
              results = {k: sum(v)/len(v) for k, v in aggregates.items()}
              for symbol, avg in results.items():
                  table.put_item(Item={
                      "symbol": symbol,
                      "Timestamp": int(datetime.utcnow().timestamp()),
                      "average": avg,
                      "TTL": int(datetime.utcnow().timestamp()) + 86400
                  })
              print(f"Stored averages: {results}")

#########################
# Lambda Invoke Permission
#########################

  AggregatorInvokePermission:
    Type: AWS::Lambda::Permission
    DependsOn: AggregatorLambda
    Properties:
      Action: lambda:InvokeFunction
      FunctionName: !Ref AggregatorLambda
      Principal: s3.amazonaws.com


###################
#    S3 Buckets   #
###################

  S3Raw:
  Type: AWS::S3::Bucket
  Properties:
    BucketName: 'yossef-raw-bucket'
    AccessControl: Private
    VersioningConfiguration:
      Status: Enabled

S3Processed:
  Type: AWS::S3::Bucket
  DependsOn:
    - AggregatorLambda
    - AggregatorInvokePermission
  Properties:
    BucketName: 'yossef-processed-bucket'
    AccessControl: Private
    VersioningConfiguration:
      Status: Enabled
    NotificationConfiguration:
      LambdaConfigurations:
        - Event: "s3:ObjectCreated:*"
          Function: !GetAtt AggregatorLambda.Arn

S3ProcessedPolicy:
  Type: AWS::S3::BucketPolicy
  Properties:
    Bucket: !Ref S3Processed
    PolicyDocument:
      Version: "2012-10-17"
      Statement:
        - Sid: "AllowAccountAthenaAndQuickSightAccess"
          Effect: "Allow"
          Principal:
            AWS: !Sub "arn:aws:iam::${AWS::AccountId}:root"
          Action:
            - "s3:GetObject"
            - "s3:PutObject"
            - "s3:ListBucket"
          Resource:
            - !Sub "arn:aws:s3:::${S3Processed}"
            - !Sub "arn:aws:s3:::${S3Processed}/*"

####################
#  Event Sources   #
####################

  ValidatorEnricherEventSourceMapping:
    Type: AWS::Lambda::EventSourceMapping
    Properties:
      EventSourceArn: !ImportValue Streaming-KinesisStreamArn
      FunctionName: !Ref ValidatorEnricherLambda
      StartingPosition: LATEST
      BatchSize: 10
      Enabled: true

##################
#    Outputs     #
##################

Outputs:
  ValidatorEnricherLambda:
    Description: 'Validator and Enricher Lambda Function'
    Value: !Ref ValidatorEnricherLambda
    Export:
      Name: "ValidatorEnricherLambda"

  AggregatorLambda:
    Description: 'Aggregator Lambda Function'
    Value: !Ref AggregatorLambda
    Export:
      Name: "AggregatorLambda"

  RawS3Bucket:
    Description: Raw S3 Bucket Name
    Value: !Ref S3Raw
    Export:
      Name: "BucketRaw"
  
  ProcessedS3Bucket:
    Description: Processed S3 Bucket Name
    Value: !Ref S3Processed
    Export:
      Name: "BucketProcessed"
